---
title: "Practical Machine Learning Course Project"
output: 
  html_document: 
    fig_caption: yes
    fig_height: 7
    fig_width: 9
    keep_md: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Quality of Activities as measured by Personal Activity Measurement Devices

##Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

##Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The complete data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

## Synopsis

The training and test data of measurements from personal activity measurement devices are used from the following study:

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13), stuttgart, Germany: ACM SIGCHI, 2013.

The aim of this project is to "predict the manner in which they did the exercise."

The data is analysed and the report is generated to describe:

1. Prediction Model building    
2. Use of Cross Validation
3. Expected out of sample error
4. Reason for modeling and prediction choices

Ultimately, the prediction model is to be run on the test data to predict the outcome of 20 different test cases.

The report briefly describes the "Components of a Predictor" and defines five stages:      a) Question, b) Input Data, c) Features, d) Algorithm, e) Parameters and f) Evaluation

##LOAD LIBRARIES
```{r load libraries}
require(AppliedPredictiveModeling)
require(caret)
require(rattle)
require(rpart)
require(rpart.plot)
require(randomForest)
require(corrplot)
require(Rtsne)
require(xgboost)
require(stats)
require(knitr)
require(ggplot2)
require(downloader)
require(e1071)
require(Ckmeans.1d.dp)
```

## QUESTION

In the aforementioned study, six participants participated in a dumbell lifting exercise five different ways. The five ways, as described in the study, were "exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes."

By processing data gathered from accelerometers on the belt, forearm, arm, and dumbell of the participants in a machine learning algorithm, the question is can the appropriate activity quality (class A-E) be predicted?

## INPUT DATA

The first step is to import the data and to verify that the training data and the test data are identical.

```{r set directory}
setwd("C:/Users/Home/Downloads/Coursera-DS/Course8-PracticalMachineLearning/Project")
```

URL of the training and testing data
```{r download data}
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <-  "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# if directory does not exist, create new
if (!dir.exists("./data")) {
  dir.create("./data")
}

# file names
train_name <-"./data/pml-training.csv"
test_name <- "./data/pml-testing.csv"

# if files does not exist, download the files
if (!file.exists(train_name)) {
  download.file(train_url, destfile=train_name)
}
if (!file.exists(test_name)) {
  download.file(test_url, destfile=test_name)
}
# load the CSV files as data.frame 
train <- read.csv("./data/pml-training.csv")
test <- read.csv("./data/pml-testing.csv")
dim(train)
```
```{r test set dim}
dim(test)
```
```{r train set columns}
names(train)
```
The raw training data has 19622 rows of observations and 158 features (predictors). Column X is unusable row number. While the testing data has 20 rows and the same 158 features. There is one column of target outcome named classe.

##Data cleaning

First, extract target outcome (the activity quality) from training data, so now the training data contains only the predictors (the activity monitors).

```{r data cleaning outcome levels}
# target outcome (label)
outcome.org <- train[, "classe"]
outcome <- outcome.org 
levels(outcome)
```

Outcome has 5 levels in character format.
Convert the outcome to numeric, because XGBoost gradient booster only recognizes numeric data.

```{r data cleaning change type}
# convert character levels to numeric
num.class <- length(levels(outcome))
levels(outcome) <- 1:num.class
head(outcome)
```

The outcome is removed from training data.
```{r data cleaning remove outcome}
# remove outcome from train
train$classe <- NULL
```

The assignment rubric asks to use data from accelerometers on the belt, forearm, arm, and dumbell, so the features are extracted based on these keywords.

```{r data cleaning filter}
# filter columns on: belt, forearm, arm, dumbell
filter <- grepl("belt|arm|dumbell", names(train))
train <- train[, filter]
test <- test[, filter]
```

Instead of less-accurate imputation of missing data, remove all columns with NA values.

```{r data cleaning remove NA}
# remove columns with NA, use test data as referral for NA
cols.without.na <- colSums(is.na(test)) == 0
train <- train[, cols.without.na]
test <- test[, cols.without.na]
```

##Preprocessing
Check for features's variance

Based on the principal component analysis PCA, it is important that features have maximum variance for maximum uniqueness, so that each feature is as distant as possible (as orthogonal as possible) from the other features.

```{r Preprocessing check zero variance}
# check for zero variance
zero.var <- nearZeroVar(train, saveMetrics=TRUE)
zero.var
```

There are no features without variability (all has enough variance). So there is no feature to be removed further.
Plot of relationship between features and outcome

Plot the relationship between features and outcome. From the plot below, each features has relatively the same distribution among the 5 outcome levels (A, B, C, D, E).

```{r Preprocessing features plot}
featurePlot(train, outcome.org, "strip")
```

Plot of correlation matrix

Plot a correlation matrix between features.
A good set of features is when they are highly uncorrelated (orthogonal) each others. The plot below shows average of correlation is not too high, so I choose to not perform further PCA preprocessing.

```{r Preprocessing correlation matrix}
corrplot.mixed(cor(train), lower="circle", upper="color", 
               tl.pos="lt", diag="n", order="hclust", hclust.method="complete")
```

tSNE plot

A tSNE (t-Distributed Stochastic Neighbor Embedding) visualization is 2D plot of multidimensional features, that is multidimensional reduction into 2D plane. In the tSNE plot below there is no clear separation of clustering of the 5 levels of outcome (A, B, C, D, E). So it hardly gets conclusion for manually building any regression equation from the irregularity.

```{r Preprocessing tSNE plot}
# t-Distributed Stochastic Neighbor Embedding
tsne <- Rtsne(as.matrix(train), check_duplicates=FALSE, pca=TRUE, 
              perplexity=30, theta=0.5, dims=2)
```

```{r Preprocessing Embedding of classe outcome}
embedding <- as.data.frame(tsne$Y)
embedding$Class <- outcome.org
g <- ggplot(embedding, aes(x=V1, y=V2, color=Class)) +
  geom_point(size=1.25) +
  guides(colour=guide_legend(override.aes=list(size=6))) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2D Embedding of 'Classe' Outcome") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank())
print(g)
```

##Build machine learning model

Now build a machine learning model to predict activity quality (classe outcome) from the activity monitors (the features or predictors) by using XGBoost extreme gradient boosting algorithm.

###XGBoost data

XGBoost supports only numeric matrix data. Converting all training, testing and outcome data to matrix.

```{r Machine Learning Model}
# convert data to matrix
train.matrix <- as.matrix(train)
mode(train.matrix) <- "numeric"
test.matrix <- as.matrix(test)
mode(test.matrix) <- "numeric"
# convert outcome from factor to numeric matrix 
#   xgboost takes multi-labels in [0, numOfClass)
y <- as.matrix(as.integer(outcome)-1)
```


###XGBoost parameters

Set XGBoost parameters for cross validation and training.
Set a multiclass classification objective as the gradient boosting's learning function.
Set evaluation metric to merror, multiclass error rate.

```{r xgboost parameters}
# xgboost parameters
param <- list("objective" = "multi:softprob",    # multiclass classification 
              "num_class" = num.class,    # number of classes 
              "eval_metric" = "merror",    # evaluation metric 
              "nthread" = 8,   # number of threads to be used 
              "max_depth" = 16,    # maximum depth of tree 
              "eta" = 0.3,    # step size shrinkage 
              "gamma" = 0,    # minimum loss reduction 
              "subsample" = 1,    # part of data instances to grow tree 
              "colsample_bytree" = 1,  # subsample ratio of columns when constructing each tree 
              "min_child_weight" = 12  # minimum sum of instance weight needed in a child 
              )
```


###Expected error rate

Expected error rate is less than 1% for a good classification. Do cross validation to estimate the error rate using 4-fold cross validation, with 200 epochs to reach the expected error rate of less than 1%.

#### 4-fold cross validation

```{r cross validation}
# set random seed, for reproducibility 
set.seed(1234)
# k-fold cross validation, with timing
nround.cv <- 200
system.time( bst.cv <- xgb.cv(param=param, data=train.matrix, label=y, 
              nfold=4, nrounds=nround.cv, prediction=TRUE, verbose=FALSE) )
```

Elapsed time is less than 90 seconds (1.5 minutes).

```{r cross validation tail}
tail(bst.cv$dt) 
```

From the cross validation, choose index with minimum multiclass error rate.
Index will be used in the model training to fulfill expected minimum error rate of < 1%.

```{r minimum error index}
# index of minimum merror
min.merror.idx <- which.min(bst.cv$dt[, test.merror.mean]) 
min.merror.idx 
```

```{r minimum error}
# minimum merror
bst.cv$dt[min.merror.idx,]
```

Best cross-validation's minimum error rate test.merror.mean is around 0.0055 (0.55%), happened at 187th iteration.

##Confusion matrix

Tabulates the cross-validation's predictions of the model against the truths.
```{r compare cross validation vs. truth}
# get CV's prediction decoding
pred.cv <- matrix(bst.cv$pred, nrow=length(bst.cv$pred)/num.class, ncol=num.class)
pred.cv <- max.col(pred.cv, "last")
# confusion matrix
confusionMatrix(factor(y+1), factor(pred.cv))
```

Confusion matrix shows concentration of correct predictions is on the diagonal, as expected.

The average accuracy is 99.44%, with error rate is 0.56%. So, expected error rate of less than 1% is fulfilled.

##Model training

Fit the XGBoost gradient boosting model on all of the training data.

```{r real model fit}
# real model fit training, with full data
system.time( bst <- xgboost(param=param, data=train.matrix, label=y, 
                           nrounds=min.merror.idx, verbose=0) )
```

Time elapsed is around 26 seconds.

##Predicting the testing data

```{r predict test data}
# xgboost predict test data using the trained model
pred <- predict(bst, test.matrix)  
head(pred, 10)  
```

Post-processing

Output of prediction is the predicted probability of the 5 levels (columns) of outcome.
Decode the quantitative 5 levels of outcomes to qualitative letters (A, B, C, D, E).

```{r prediction output}
# decode prediction
pred <- matrix(pred, nrow=num.class, ncol=length(pred)/num.class)
pred <- t(pred)
pred <- max.col(pred, "last")
pred.char <- toupper(letters[pred])
```

```{r predict test data result}
#pred.char
#(The prediction result pred.char is not displayed intentionally due to Honour Code, because it is the answer of the "project submission" part.)
```

##Feature importance

```{r feature importance}
# get the trained model
model <- xgb.dump(bst, with.stats=TRUE)
# get the feature real names
names <- dimnames(train.matrix)[[2]]
# compute feature importance matrix
importance_matrix <- xgb.importance(names, model=bst)

# plot
gp <- xgb.plot.importance(importance_matrix)
print(gp) 
```
Feature importance plot is useful to select only best features with highest correlation to the outcome(s). To improve model fitting performance (time or overfitting), less important features can be removed.

##Creating submission files

```{r creating submission file}
path <- "./answer"
pml_write_files <- function(x) {
    n <- length(x)
    for(i in 1: n) {
        filename <- paste0("problem_id_", i, ".txt")
        write.table(x[i], file=file.path(path, filename), 
                    quote=FALSE, row.names=FALSE, col.names=FALSE)
    }
}
pml_write_files(pred.char)
```















